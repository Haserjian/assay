{
  "tool": "assay-scan",
  "status": "fail",
  "summary": {
    "sites_total": 5,
    "instrumented": 0,
    "uninstrumented": 5,
    "high": 4,
    "medium": 1,
    "low": 0
  },
  "findings": [
    {
      "path": "gptme/llm/llm_anthropic.py",
      "line": 410,
      "call": "_anthropic.messages.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.anthropic import patch; patch()"
    },
    {
      "path": "gptme/llm/llm_openai.py",
      "line": 528,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "gptme/llm/llm_openai.py",
      "line": 621,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "gptme/tools/_browser_perplexity.py",
      "line": 83,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "scripts/gpt_todoer.py",
      "line": 94,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    }
  ],
  "next_command": "# Add to your entrypoint:\nfrom assay.integrations.openai import patch; patch()\n# Then: assay run -- python your_app.py"
}
