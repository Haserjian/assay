{
  "tool": "assay-scan",
  "status": "fail",
  "summary": {
    "sites_total": 31,
    "instrumented": 0,
    "uninstrumented": 31,
    "high": 20,
    "medium": 11,
    "low": 0
  },
  "findings": [
    {
      "path": "browser_use/actor/playground/flights.py",
      "line": 5,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/actor/playground/mixed_automation.py",
      "line": 22,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/cli.py",
      "line": 366,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/cli.py",
      "line": 371,
      "call": "ChatAnthropic",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/cli.py",
      "line": 386,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/cli.py",
      "line": 388,
      "call": "ChatAnthropic",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/llm/anthropic/chat.py",
      "line": 145,
      "call": "messages.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.anthropic import patch; patch()"
    },
    {
      "path": "browser_use/llm/anthropic/chat.py",
      "line": 196,
      "call": "messages.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.anthropic import patch; patch()"
    },
    {
      "path": "browser_use/llm/aws/chat_anthropic.py",
      "line": 165,
      "call": "messages.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.anthropic import patch; patch()"
    },
    {
      "path": "browser_use/llm/aws/chat_anthropic.py",
      "line": 207,
      "call": "messages.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.anthropic import patch; patch()"
    },
    {
      "path": "browser_use/llm/cerebras/chat.py",
      "line": 118,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/cerebras/chat.py",
      "line": 164,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/deepseek/chat.py",
      "line": 121,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/deepseek/chat.py",
      "line": 157,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/deepseek/chat.py",
      "line": 194,
      "call": "client.chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/groq/chat.py",
      "line": 153,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/groq/chat.py",
      "line": 203,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/groq/chat.py",
      "line": 216,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/models.py",
      "line": 167,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/llm/openai/chat.py",
      "line": 200,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/openai/chat.py",
      "line": 250,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/openai/chat.py",
      "line": 257,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/openrouter/chat.py",
      "line": 147,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/openrouter/chat.py",
      "line": 174,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/vercel/chat.py",
      "line": 395,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/vercel/chat.py",
      "line": 446,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/llm/vercel/chat.py",
      "line": 498,
      "call": "chat.completions.create",
      "confidence": "high",
      "instrumented": false,
      "fix": "from assay.integrations.openai import patch; patch()"
    },
    {
      "path": "browser_use/mcp/server.py",
      "line": 561,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/mcp/server.py",
      "line": 617,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/skill_cli/commands/agent.py",
      "line": 89,
      "call": "ChatOpenAI",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    },
    {
      "path": "browser_use/skill_cli/commands/agent.py",
      "line": 98,
      "call": "ChatAnthropic",
      "confidence": "medium",
      "instrumented": false,
      "fix": "from assay.integrations.langchain import patch; patch()"
    }
  ],
  "next_command": "# Add to your entrypoint:\nfrom assay.integrations.openai import patch; patch()\n# Then: assay run -- python your_app.py"
}
